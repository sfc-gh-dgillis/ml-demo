{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "t4dxzex5axia53n5tjag",
   "authorId": "4931222243105",
   "authorName": "DGILLIS",
   "authorEmail": "daniel.gillis@snowflake.com",
   "sessionId": "977dca7a-679e-4cd5-b5f7-ae6b2d3d4abb",
   "lastEditTime": 1745983921763
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell1",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nfrom snowflake.ml.ray.datasource import SFStageImageDataSource, SFStageTextDataSource\n\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n"
  },
  {
   "cell_type": "markdown",
   "id": "e61e1748-e726-4927-8f49-38647e3f28f4",
   "metadata": {
    "collapsed": false,
    "name": "cell10",
    "resultHeight": 46
   },
   "source": [
    "### Create a Data Source to read unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fe16b-c1df-4409-8199-ea99b4fe3769",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# reading the image, resize the image to 256 x 256 to lower memory requirement and help performance\nimage_source = SFStageImageDataSource(\n    stage_location = \"@DATA_STAGE_RAY/images/\",\n    database = \"ST_DB\",\n    schema = \"ST_SCHEMA\",\n    image_size=(256, 256),\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324e409-b4c5-4405-ad1c-267831be1773",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": "# reading the label\n# data is loaded after these two steps\n# create pointer to data in stages\nlabel_source = SFStageTextDataSource(\n    stage_location = \"@DATA_STAGE_RAY/labels/\",\n    database = \"ST_DB\",\n    schema = \"ST_SCHEMA\",\n)"
  },
  {
   "cell_type": "code",
   "id": "71a611a0-60fb-464c-aa60-a77a70c34c0a",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "# configure logger and only log critical errors\nimport ray\nimport logging\n\ndef configure_ray_logger() -> None:\n    #Configure Ray logging\n    ray_logger = logging.getLogger(\"ray\")\n    ray_logger.setLevel(logging.CRITICAL)\n\n    data_logger = logging.getLogger(\"ray.data\")\n    data_logger.setLevel(logging.CRITICAL)\n\n    #Configure root logger\n    logger = logging.getLogger()\n    logger.setLevel(logging.CRITICAL)\n\n    #Configure Ray's data context\n    context = ray.data.DataContext.get_current()\n    context.execution_options.verbose_progress = False\n    context.enable_operator_progress_bars = False\n\nconfigure_ray_logger()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "206f9a9e-df5b-4a75-8f6f-1e4fbb6fbdd3",
   "metadata": {
    "collapsed": false,
    "name": "cell11",
    "resultHeight": 46
   },
   "source": [
    "### Load into a ray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc513b-b40c-4b27-b429-a04bfb18b962",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "resultHeight": 71,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# everything is lazy loaded\n# turns data source into a dataset\nimage_ds = ray.data.read_datasource(image_source)"
  },
  {
   "cell_type": "markdown",
   "id": "9f2863ec-ab55-44c7-8801-4578d384912f",
   "metadata": {
    "name": "cell12",
    "collapsed": false
   },
   "source": "Now we can print the image dataset schema, which has the shape of the image we set earlier and the file name."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72791f82-627f-4d0e-89cd-3b314154da14",
   "metadata": {
    "language": "python",
    "name": "cell41"
   },
   "outputs": [],
   "source": [
    "print(image_ds.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96830c4-d4e7-4709-8c6b-8066772a4442",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "Lazy Loaded 1,500 images and print a couple of images which consist of an array of pixels and the file name"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11781ea0-dfc8-42a9-baef-3f5ce7b88280",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "print(f'Total load {image_ds.count()} images')\n",
    "image_ds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0b330-33bf-4033-bacb-fd1301933302",
   "metadata": {
    "language": "python",
    "name": "cell16",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# read the label dataset, use 6 workers to read from the stage concurrently\nlabel_ds = ray.data.read_datasource(label_source, concurrency=6)"
  },
  {
   "cell_type": "markdown",
   "id": "85d00eb1-92d1-489d-a502-1aaea33964a2",
   "metadata": {
    "name": "cell18",
    "collapsed": false
   },
   "source": "Print out the label dataset schema. The label dataset looks like:\n\n```text\n466 441 493 470 3\n454 300 493 396 2\n331 248 364 283 4\n221 314 253 350 4\n151 149 182 175 5\n492 28 525 55 6\n424 24 461 53 6\n250 341 278 370 6\n539 259 592 316 1\n89 469 127 497 5\n```\n\nEach row is delimited by a newline character, so that doesn't need to be called out. It will be handled automatically."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb066c-62be-476a-825c-5d4f66a6b6f5",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "print(label_ds.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bce596-2b7a-43db-ace2-38befe73fb8d",
   "metadata": {
    "language": "python",
    "name": "cell42"
   },
   "outputs": [],
   "source": "print(label_ds.show(1))"
  },
  {
   "cell_type": "markdown",
   "id": "28a3dd4a-0da6-4072-a0c9-faeb0b127bb8",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": "### Batch Process both datasets to include addition columns\n\n**Image Dataset**: add a join key, encode the images, standardize image\n\n**Label Dataset**: add a join key, interpret the labels\n\nFunction process_image adds grayscale image standardization, then encodes the image so it can be saved to a Snowflake table and then creates a join key from the filename pattern to be able to link an image to a label.\n\nFinally, we take this function and run the ray dataset map method to apply the function to every row of the dataset.\n\nThis mapping again is happening lazily, which means you can have a massive dataset and allow ray to handle the processing in the most efficient way possible so you can focus on business logic."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b19b8c-ed51-45a3-b277-003a5d16fbf6",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": "import numpy as np\nfrom typing import Dict\nimport base64\nimport os\n\ndef process_image(row):\n    # If grayscale (2D), convert to 3D\n    img = row['image']\n    if len(img.shape) == 2:\n        row['image'] = np.stack([img] * 3, axis=-1)  # Duplicate grayscale channel 3 times\n\n    encoded_image = base64.b64encode(row['image'])\n    row['encoded_image'] = encoded_image\n\n    fn = row['file_name']\n    join_id = os.path.splitext(fn)[0].split('/')[-1]\n    row['join_id'] = join_id\n    return row\n\n# processed_image_ds = image_ds.map_batches(convert_to_torch, concurrency=4)\nprocessed_image_ds = image_ds.map(process_image)"
  },
  {
   "cell_type": "markdown",
   "id": "8206e846-8082-4ce6-853d-fc68e6718b8e",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "`processed_image_ds` is a processed ray dataset. Image has been processed using function above (lazily) and we're now "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2af3b0-968c-4f43-9a89-c68df5cb899a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "# force trigger operation for 1 image\nprocessed_image_ds.show(1)"
  },
  {
   "cell_type": "markdown",
   "id": "d823d775-6049-4730-929e-44bf6cc787f4",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "Split the values from the label files to be able to store bounding box coordinates individually."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b39bfc-ab79-4bf9-91a0-e51122622664",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": "import os\n\ndef expand_label_column(batch: pd.DataFrame) -> pd.DataFrame:\n    xmin_list = []\n    ymin_list = []\n    xmax_list = []\n    ymax_list = []\n    class_list = []\n    file_names = []\n    ids = []\n    \n    # Process each row\n    for _, row in batch.iterrows():\n        # Split the text and convert to list\n        values = row['text'].strip().split()\n        \n        # Ensure we have exactly 5 values\n        if len(values) != 5:\n            raise ValueError(f\"Expected 5 values in text, but got {len(values)} values\")\n            \n        # Add values to respective lists\n        xmin_list.append(float(values[0]))\n        ymin_list.append(float(values[1]))\n        xmax_list.append(float(values[2]))\n        ymax_list.append(float(values[3]))\n        class_list.append(int(values[4]))\n        file_name = row['file_name']\n        file_names.append(file_name)\n        ids.append(os.path.splitext(file_name)[0].split('/')[-1] + '_test')\n    \n    # Create new dataframe\n    new_df = pd.DataFrame({\n        'join_id': ids,\n        'file_name': file_names,\n        'xmin': xmin_list,\n        'ymin': ymin_list,\n        'xmax': xmax_list,\n        'ymax': ymax_list,\n        'class': class_list,\n    })\n    return new_df \n\nprocessed_label_ds = label_ds.map_batches(expand_label_column, concurrency=6, batch_format='pandas')"
  },
  {
   "cell_type": "markdown",
   "id": "b2515e23-03e8-4eb4-946a-580d146f40d9",
   "metadata": {
    "name": "cell28",
    "collapsed": false
   },
   "source": "Print first record - now everything is nicely parsed."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c06a4-3ab3-445b-bcc3-dd26ee716b4a",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "processed_label_ds.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98bd97-140d-4e81-a760-b37a5cfd0a5e",
   "metadata": {
    "collapsed": false,
    "name": "cell21"
   },
   "source": "### Merge image source and label source into a single dataset\n\nWe have two ways of achieving this: 1) if customer is more familiar with `pandas.Dataframe` and if the data fits into memory, then we can convert all data into pandas (or write into snowflake) and do the rest of the ops. 2) If the data does not fit into memory, we can directly leverage ray dataset to do the processing. \n\n**Note**: Ray dataset is not naturally architechted to support join ops, so it's better for to use other method (in memory / snowflake) to perform joins"
  },
  {
   "cell_type": "markdown",
   "id": "5d43a6e8-3c3b-42c6-bac3-8dffb59acd6b",
   "metadata": {
    "collapsed": false,
    "name": "cell27"
   },
   "source": "#### Method 1: convert both ray datasets into pandas dataframe and perform joins"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a18c6e-9851-4fb9-98e1-2ff5aef48b29",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": "# show how to convert a ray dataset to a panda dataframe\nimage_df = processed_image_ds.drop_columns(cols=['image']).to_pandas()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6ca4a-bedd-494c-a245-e799becc344b",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": "# pandas - return first 5 rows\nimage_df.head()"
  },
  {
   "cell_type": "markdown",
   "id": "a068cbe9-9efb-454f-a8c2-5830495c7008",
   "metadata": {
    "name": "cell29",
    "collapsed": false
   },
   "source": "Do the same thing for the label - convert ray dataset to a panda dataframe and print first 5 rows"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f04b19-aa68-4671-9463-cb3d1d16e1a4",
   "metadata": {
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": [
    "label_df = processed_label_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43965eb1-e487-4c75-938d-cda48e871a87",
   "metadata": {
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c756579-305e-4ac7-b7f1-54c1341606c8",
   "metadata": {
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "# perform merge \n",
    "merged_train_df = pd.merge(image_df, label_df, how='inner', on='join_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe32e8-7525-4385-812f-bd802d7e95ec",
   "metadata": {
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "merged_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a2f50-8c46-4b29-b9ea-f12458100444",
   "metadata": {
    "collapsed": false,
    "name": "cell13",
    "resultHeight": 46
   },
   "source": [
    "## Save the Transformed Dataset to a snowflake table\n",
    "Customer may also save the processed image dataset and label dataset into snowflake easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad11e31-bc2a-45e6-8b6a-c3ea08b2ea9b",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "from snowflake.ml.ray.datasink import SnowflakeTableDatasink\n\nsession.use_role(role=\"SYSADMIN\")\nsession.use_database(database=\"ST_DB\")\nsession.use_schema(schema=\"ST_SCHEMA\")\n\ntable_to_save = \"RAY_DEMO_JAN21_IMAGE_DS\"\ndatasink = SnowflakeTableDatasink(\n    table_name=table_to_save,\n    database = \"ST_DB\",\n    schema = \"ST_SCHEMA\",\n    auto_create_table=True,\n    override=True,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c406f-a2f0-4c68-a82b-d06c40610130",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "resultHeight": 41334
   },
   "outputs": [],
   "source": [
    "processed_image_ds.drop_columns(cols=['image']).write_datasink(datasink, concurrency=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e353f-4334-4f76-a1ac-8bcd96c8d6b8",
   "metadata": {
    "language": "sql",
    "name": "cell35"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM RAY_DEMO_JAN21_IMAGE_DS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c702d-338c-47ac-a4f8-6afc208e1ba3",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "table_to_save = \"RAY_DEMO_JAN21_LABEL_DS\"\n",
    "datasink = SnowflakeTableDatasink(\n",
    "    table_name=table_to_save,\n",
    "    database = \"ST_DB\",\n",
    "    schema = \"ST_SCHEMA\",\n",
    "    auto_create_table=True,\n",
    "    override=True,\n",
    ")\n",
    "processed_label_ds.write_datasink(datasink, concurrency=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340d435d-57ce-461c-b72f-051e80d1ce55",
   "metadata": {
    "language": "sql",
    "name": "cell38"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM RAY_DEMO_JAN21_LABEL_DS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9e512-cab3-4f39-9b4e-be428df0aecb",
   "metadata": {
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": [
    "table_to_save = \"RAY_DEMO_JAN21_COMINED_DS\"\n",
    "datasink = SnowflakeTableDatasink(\n",
    "    table_name=table_to_save,\n",
    "    database = \"ST_DB\",\n",
    "    schema = \"ST_SCHEMA\",\n",
    "    auto_create_table=True,\n",
    "    override=True,\n",
    ")\n",
    "processed_label_ds.write_datasink(datasink, concurrency=4)"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb03c326-2023-43d5-be69-9e744ef023ba",
   "metadata": {
    "language": "sql",
    "name": "cell30"
   },
   "outputs": [],
   "source": "SELECT * FROM RAY_DEMO_JAN21_COMINED_DS;",
   "execution_count": null
  }
 ]
}