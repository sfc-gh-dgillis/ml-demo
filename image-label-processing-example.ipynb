{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell1",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from snowflake.ml.ray.datasource import SFStageImageDataSource, SFStageTextDataSource\n",
    "\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e1748-e726-4927-8f49-38647e3f28f4",
   "metadata": {
    "collapsed": false,
    "name": "cell10",
    "resultHeight": 46
   },
   "source": [
    "### Create a Data Source to read unstructured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71fe16b-c1df-4409-8199-ea99b4fe3769",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# reading the image, resize the image to 256 x 256 to lower memory requirement and help performance\n",
    "image_source = SFStageImageDataSource(\n",
    "    stage_location = \"@DATA_STAGE_RAY/images/\",\n",
    "    database = \"ST_DB\",\n",
    "    schema = \"ST_SCHEMA\",\n",
    "    image_size=(256, 256),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2324e409-b4c5-4405-ad1c-267831be1773",
   "metadata": {
    "language": "python",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "# reading the label\n",
    "# data is loaded after these two steps\n",
    "# create pointer to data in stages\n",
    "label_source = SFStageTextDataSource(\n",
    "    stage_location = \"@DATA_STAGE_RAY/labels/\",\n",
    "    database = \"ST_DB\",\n",
    "    schema = \"ST_SCHEMA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f9a9e-df5b-4a75-8f6f-1e4fbb6fbdd3",
   "metadata": {
    "collapsed": false,
    "name": "cell11",
    "resultHeight": 46
   },
   "source": [
    "### Load into a ray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc513b-b40c-4b27-b429-a04bfb18b962",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "resultHeight": 71
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "# everything is lazy loaded\n",
    "# turns data source into a dataset\n",
    "image_ds = ray.data.read_datasource(image_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72791f82-627f-4d0e-89cd-3b314154da14",
   "metadata": {
    "language": "python",
    "name": "cell41"
   },
   "outputs": [],
   "source": [
    "print(image_ds.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11781ea0-dfc8-42a9-baef-3f5ce7b88280",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "print(f'Total load {image_ds.count()} images')\n",
    "image_ds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0b330-33bf-4033-bacb-fd1301933302",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "# read the dataset, use 8 workers to read from the stage concurrently\n",
    "label_ds = ray.data.read_datasource(label_source, concurrency=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb066c-62be-476a-825c-5d4f66a6b6f5",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "print(label_ds.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bce596-2b7a-43db-ace2-38befe73fb8d",
   "metadata": {
    "language": "python",
    "name": "cell42"
   },
   "outputs": [],
   "source": [
    "label_ds.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a3dd4a-0da6-4072-a0c9-faeb0b127bb8",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "### Batch Process both dataset to include addition columns\n",
    "**Image Dataset**: add a join key, encode the images, standardize image\n",
    "**Label Dataset**: add a join key, interrpet the labels\n",
    "\n",
    "Image standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b19b8c-ed51-45a3-b277-003a5d16fbf6",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "import base64\n",
    "import os\n",
    "\n",
    "def process_image(row):\n",
    "    # If grayscale (2D), convert to 3D\n",
    "    img = row['image']\n",
    "    if len(img.shape) == 2:\n",
    "        row['image'] = np.stack([img] * 3, axis=-1)  # Duplicate grayscale channel 3 times\n",
    "\n",
    "    encoded_image = base64.b64encode(row['image'])\n",
    "    row['encoded_image'] = encoded_image\n",
    "\n",
    "    fn = row['file_name']\n",
    "    join_id = os.path.splitext(fn)[0].split('/')[-1]\n",
    "    row['join_id'] = join_id\n",
    "    return row\n",
    "\n",
    "# processed_image_ds = image_ds.map_batches(convert_to_torch, concurrency=4)\n",
    "processed_image_ds = image_ds.map(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2af3b0-968c-4f43-9a89-c68df5cb899a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# force trigger operation for 1 image\n",
    "processed_image_ds.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b39bfc-ab79-4bf9-91a0-e51122622664",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def expand_label_column(batch: pd.DataFrame) -> pd.DataFrame:\n",
    "    xmin_list = []\n",
    "    ymin_list = []\n",
    "    xmax_list = []\n",
    "    ymax_list = []\n",
    "    class_list = []\n",
    "    file_names = []\n",
    "    ids = []\n",
    "    \n",
    "    # Process each row\n",
    "    for _, row in batch.iterrows():\n",
    "        # Split the text and convert to list\n",
    "        values = row['text'].strip().split()\n",
    "        \n",
    "        # Ensure we have exactly 5 values\n",
    "        if len(values) != 5:\n",
    "            raise ValueError(f\"Expected 5 values in text, but got {len(values)} values\")\n",
    "            \n",
    "        # Add values to respective lists\n",
    "        xmin_list.append(float(values[0]))\n",
    "        ymin_list.append(float(values[1]))\n",
    "        xmax_list.append(float(values[2]))\n",
    "        ymax_list.append(float(values[3]))\n",
    "        class_list.append(int(values[4]))\n",
    "        file_name = row['file_name']\n",
    "        file_names.append(file_name)\n",
    "        ids.append(os.path.splitext(file_name)[0].split('/')[-1] + '_test')\n",
    "    \n",
    "    # Create new dataframe\n",
    "    new_df = pd.DataFrame({\n",
    "        'join_id': ids,\n",
    "        'file_name': file_names,\n",
    "        'xmin': xmin_list,\n",
    "        'ymin': ymin_list,\n",
    "        'xmax': xmax_list,\n",
    "        'ymax': ymax_list,\n",
    "        'class': class_list,\n",
    "    })\n",
    "    return new_df \n",
    "\n",
    "processed_label_ds = label_ds.map_batches(expand_label_column, concurrency=6, batch_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0c06a4-3ab3-445b-bcc3-dd26ee716b4a",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "processed_label_ds.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98bd97-140d-4e81-a760-b37a5cfd0a5e",
   "metadata": {
    "collapsed": false,
    "name": "cell21"
   },
   "source": [
    "### Merge image source and label source into a single dataset\n",
    "We have two ways of achieving this: 1) if customer is more famaliar with `pandas.Dataframe` and if the data fit into memory, then we can convert all data into pandas (or write into snowflake) and do the rest of the ops. 2) If the data does not fit into memory, we can directly leverage ray dataset to do the processing. \n",
    "\n",
    "**Note**: Ray dataset is not naturally architeched to support join ops, so it's better for to use other method (in memory / snowflake) to perform joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd3c6f-dbcf-4769-8d2b-66ed7a001b2b",
   "metadata": {
    "collapsed": false,
    "name": "cell22"
   },
   "source": [
    "#### Let's start with method 2 just to show it is possbile to do joins with ray as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2079121d-3084-4704-8e91-ff94d3ab7fc5",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "# currently ray dataset does not offer a JOIN between two dataset, we can offer a utility function \n",
    "# for customer to perform joins in container runtime\n",
    "# skip this\n",
    "\n",
    "joined_ds = optimized_dataset_join(\n",
    "    processed_image_ds,\n",
    "    processed_label_ds,\n",
    "    left_on='join_id',\n",
    "    right_on='join_id'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cd4a91-d259-4816-bf92-7d379e64854f",
   "metadata": {
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": [
    "# This call currently is slow\n",
    "# skip this\n",
    "\n",
    "joined_ds.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d43a6e8-3c3b-42c6-bac3-8dffb59acd6b",
   "metadata": {
    "collapsed": false,
    "name": "cell27"
   },
   "source": [
    "#### Method 1: convert both dataset into pandas and perform joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a18c6e-9851-4fb9-98e1-2ff5aef48b29",
   "metadata": {
    "language": "python",
    "name": "cell24"
   },
   "outputs": [],
   "source": [
    "# show how to convert a ray dataset to a panda dataframe\n",
    "image_df = processed_image_ds.drop_columns(cols=['image']).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6ca4a-bedd-494c-a245-e799becc344b",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "# pandas - return first 5 rows\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f04b19-aa68-4671-9463-cb3d1d16e1a4",
   "metadata": {
    "language": "python",
    "name": "cell31"
   },
   "outputs": [],
   "source": [
    "label_df = processed_label_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43965eb1-e487-4c75-938d-cda48e871a87",
   "metadata": {
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": [
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c756579-305e-4ac7-b7f1-54c1341606c8",
   "metadata": {
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "# perform merge \n",
    "merged_train_df = pd.merge(image_df, label_df, how='inner', on='join_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe32e8-7525-4385-812f-bd802d7e95ec",
   "metadata": {
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "merged_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a2f50-8c46-4b29-b9ea-f12458100444",
   "metadata": {
    "collapsed": false,
    "name": "cell13",
    "resultHeight": 46
   },
   "source": [
    "## Save the Transformed Dataset to a snowflake table\n",
    "Customer may also save the processed image dataset and label dataset into snowflake easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad11e31-bc2a-45e6-8b6a-c3ea08b2ea9b",
   "metadata": {
    "language": "python",
    "name": "cell8",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.ray.datasink import SnowflakeTableDatasink\n",
    "\n",
    "session.use_role(role=\"ACCOUNTADMIN\")\n",
    "session.use_database(database=\"ST_DB\")\n",
    "session.use_schema(schema=\"ST_SCHEMA\")\n",
    "\n",
    "table_to_save = \"RAY_DEMO_JAN21_IMAGE_DS\"\n",
    "datasink = SnowflakeTableDatasink(\n",
    "    table_name=table_to_save,\n",
    "    database = \"ST_DB\",\n",
    "    schema = \"ST_SCHEMA\",\n",
    "    auto_create_table=True,\n",
    "    override=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c406f-a2f0-4c68-a82b-d06c40610130",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "resultHeight": 41334
   },
   "outputs": [],
   "source": [
    "processed_image_ds.drop_columns(cols=['image']).write_datasink(datasink, concurrency=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e353f-4334-4f76-a1ac-8bcd96c8d6b8",
   "metadata": {
    "language": "sql",
    "name": "cell35"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM RAY_DEMO_JAN21_IMAGE_DS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c702d-338c-47ac-a4f8-6afc208e1ba3",
   "metadata": {
    "language": "python",
    "name": "cell36"
   },
   "outputs": [],
   "source": [
    "table_to_save = \"RAY_DEMO_JAN21_LABEL_DS\"\n",
    "datasink = SnowflakeTableDatasink(\n",
    "    table_name=table_to_save,\n",
    "    database = \"ST_DB\",\n",
    "    schema = \"ST_SCHEMA\",\n",
    "    auto_create_table=True,\n",
    "    override=True,\n",
    ")\n",
    "processed_label_ds.write_datasink(datasink, concurrency=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340d435d-57ce-461c-b72f-051e80d1ce55",
   "metadata": {
    "language": "sql",
    "name": "cell38"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM RAY_DEMO_JAN21_LABEL_DS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9e512-cab3-4f39-9b4e-be428df0aecb",
   "metadata": {
    "language": "python",
    "name": "cell39"
   },
   "outputs": [],
   "source": [
    "table_to_save = \"RAY_DEMO_JAN21_COMINED_DS\"\n",
    "datasink = SnowflakeTableDatasink(\n",
    "    table_name=table_to_save,\n",
    "    database = \"ST_DB\",\n",
    "    schema = \"ST_SCHEMA\",\n",
    "    auto_create_table=True,\n",
    "    override=True,\n",
    ")\n",
    "processed_label_ds.write_datasink(datasink, concurrency=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47f327",
   "metadata": {},
   "source": [
    "### Continued: Train a Pytorch Model \n",
    "\n",
    "The following steps shows how we can use the processed snowflake table and use it to train a Pytorch Model\n",
    "\n",
    "The idea is to use the process dataframe that we just generated by Ray dataset, create a training loop that 1) defines training hyperparameter 2) define model architecture 3) distributed train the model usign multi-node cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e61eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "from torch import nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from snowflake.ml.modeling.distributors.pytorch import get_context\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ----------------------- 1. load data ---------------------------------------------\n",
    "\n",
    "# First we load the data from snowflake\n",
    "images = session.table(\"RAY_DEMO_JAN21_IMAGE_DS\")\n",
    "labels = session.table(\"RAY_DEMO_JAN21_LABEL_DS\")\n",
    "\n",
    "joined = images.join(labels, on=\"join_id\")\n",
    "\n",
    "def train_func():\n",
    "    # ----------------------- 2. define training hyperparameters ---------------------------------\n",
    "    NUM_CLASSES = 10\n",
    "    BATCH_SIZE  = 32\n",
    "    EPOCHS      = 3\n",
    "    context = get_context()\n",
    "    rank = context.get_rank()\n",
    "    local_rank = context.get_local_rank()\n",
    "    world_size = context.get_world_size()\n",
    "    dist.init_process_group(\n",
    "        backend=\"nccl\",\n",
    "        init_method=\"env://\",\n",
    "        rank=rank,\n",
    "        world_size=world_size\n",
    "    )\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    DEVICE = torch.device(f\"cuda:{local_rank}\")\n",
    "    train_ds = context.get_dataset_map()['train'].get_shard().to_torch_dataset()\n",
    "    data_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    tfm = transforms.Compose([transforms.ToTensor()])  # bytes -> CHW float-tensor\n",
    "\n",
    "    def batch_to_torch(pdf):\n",
    "        \"\"\"pandas → dict(tensors)\"\"\"\n",
    "        imgs = torch.stack([\n",
    "            tfm(Image.open(io.BytesIO(b))) for b in pdf[\"IMG\"].values\n",
    "        ])\n",
    "        boxes = torch.tensor(pdf[[\"XMIN\",\"YMIN\",\"XMAX\",\"YMAX\"]].values, dtype=torch.float32)\n",
    "        labels = torch.tensor(pdf[\"CLASS\"].values, dtype=torch.long)\n",
    "        return {\"img\": imgs, \"box\": boxes, \"cls\": labels}\n",
    "\n",
    "    # ----------------------- 3. model --------------------------------------------\n",
    "    class TinyDetector(nn.Module):\n",
    "        def __init__(self, n_cls):\n",
    "            super().__init__()\n",
    "            self.backbone = models.resnet18(weights=None)\n",
    "            feats = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.head = nn.Linear(feats, 4 + n_cls)\n",
    "\n",
    "        def forward(self, x):\n",
    "            h = self.backbone(x)\n",
    "            bbox, cls = h[:, :4], h[:, 4:]\n",
    "            return bbox, cls\n",
    "\n",
    "    net = TinyDetector(NUM_CLASSES).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(net.parameters(), lr=1e-4)\n",
    "    l_bbox = nn.SmoothL1Loss()\n",
    "    l_cls  = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ----------------------- 4. training loop ------------------------------------\n",
    "    for ep in range(EPOCHS):\n",
    "        for batch in data_loader:\n",
    "            t = batch_to_torch(batch)\n",
    "            x  = t[\"img\"].to(DEVICE)\n",
    "            yb = t[\"box\"].to(DEVICE)\n",
    "            yc = t[\"cls\"].to(DEVICE)\n",
    "\n",
    "            pb, pc = net(x)\n",
    "            loss = l_bbox(pb, yb) + l_cls(pc, yc)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        print(f\"epoch {ep+1}/{EPOCHS}  loss={loss.item():.4f}\")\n",
    "\n",
    "    print(\"✓ training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964e40f",
   "metadata": {},
   "source": [
    "### Use Snowflake Distributed Pytorch API to Train model \n",
    "The following API support train pytorch a any kinds of cluster that is available in Snowflake, including multi-GPU or model node training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d3a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Snowflake Distruptor and PyTorchDistributor\n",
    "from snowflake.ml.data.data_conenctor import DataConnector\n",
    "from snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor\n",
    "from snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig\n",
    "\n",
    "train_data_connector = DataConnector.from_dataframe(joined)\n",
    "\n",
    "# Create pytorch distributor. This will run the training function on the specified number of nodes and workers.\n",
    "# In this case it will run with 4 nodes and 1 worker per node, each work as access to 6 cpus and 1 gpu.\n",
    "pytorch_trainer = PyTorchDistributor(  \n",
    "    train_func=train_func,\n",
    "    scaling_config=PyTorchScalingConfig(  \n",
    "        num_nodes=4,  \n",
    "        num_workers_per_node=1,  \n",
    "        resource_requirements_per_worker=WorkerResourceConfig(num_cpus=6, num_gpus=1),  \n",
    "    )  \n",
    ") \n",
    "\n",
    "pytorch_trainer.run(\n",
    "    dataset_map={'train': train_data_connector}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "daniel.gillis@snowflake.com",
   "authorId": "4931222243105",
   "authorName": "DGILLIS",
   "lastEditTime": 1744402546359,
   "notebookId": "t4dxzex5axia53n5tjag",
   "sessionId": "fcf846f4-1033-49d9-a15d-3e10d623bd0b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
